# backend/agent.py
import uuid
from datetime import datetime
from typing import List, Dict, Optional
from backend.llm.llm_client import get_completion
from backend.memory.memory_manager import MemoryManager
from backend.memory.intelligent_extractor import MemoryOperationEngine
from backend.memory.advanced_retrieval import AdvancedMemoryRetrieval
import re

class MemoryAgent:
    def __init__(self, user_id: str = "default_user"):
        self.user_id = user_id
        self.memory = MemoryManager(user_id)
        self.session_id = str(uuid.uuid4())
        self.conversation_history = []
        
        # Initialize new intelligent components
        self.memory_engine = MemoryOperationEngine(self.memory)
        self.advanced_retrieval = AdvancedMemoryRetrieval(self.memory)
    
    def process_user_input(self, user_input: str) -> str:
        """Process user input with enhanced memory retrieval and storage"""
        
        # 1. Retrieve relevant memories with advanced scoring
        relevant_memories = self.advanced_retrieval.retrieve_memories_advanced(
            user_input, top_k=3, min_relevance=0.3
        )
        
        # 2. Build enhanced memory context
        memory_context = self._build_memory_context(relevant_memories)
        
        # 3. Create intelligent prompt
        prompt = self._create_intelligent_prompt(user_input, memory_context)
        
        # 4. Generate response
        response = get_completion(prompt)
        
        # 5. Clean up response
        response = self._clean_response(response)
        
        # 6. Store conversation
        self._store_conversation(user_input, response)
        
        # 7. Extract and store additional facts/preferences using LLM
        self._extract_and_store_facts_intelligent(user_input, response)
        
        return response
    
    def _build_memory_context(self, memories: List[Dict]) -> str:
        """Build enhanced memory context with scoring and metadata"""
        if not memories:
            return "No relevant previous context found."
        
        context_parts = []
        for i, memory in enumerate(memories, 1):
            content = memory.get('content', '')
            metadata = memory.get('metadata', {})
            relevance_score = memory.get('advanced_relevance_score', memory.get('similarity_score', 0.0))
            memory_type = metadata.get('memory_type', 'conversation')
            importance = metadata.get('importance', 1.0)
            confidence = metadata.get('confidence', 1.0)
            
            # Format based on memory type with enhanced information
            if memory_type == 'preference':
                context_parts.append(f"{i}. [PREFERENCE - {relevance_score:.2f}] {content}")
            elif memory_type == 'fact':
                context_parts.append(f"{i}. [FACT - {relevance_score:.2f}] {content}")
            else:
                context_parts.append(f"{i}. [CONVERSATION - {relevance_score:.2f}] {content}")
            
            # Add entity information if available
            entities = metadata.get('entities', [])
            if entities:
                context_parts.append(f"   Entities: {', '.join(entities)}")
        
        return "\n".join(context_parts)
    
    def _create_intelligent_prompt(self, user_input: str, memory_context: str) -> str:
        """Create an intelligent prompt that leverages memory effectively"""
        
        # Check if we have any relevant memories
        has_relevant_memories = memory_context != "No relevant previous context found."
        
        if has_relevant_memories:
            prompt = f"""You are a helpful AI assistant with persistent memory capabilities. You can remember previous conversations and user preferences across multiple sessions.

Use ONLY the following memories to provide personalized and contextually relevant responses:

MEMORIES:
{memory_context}

CRITICAL RULES:
- ONLY reference information that is EXPLICITLY mentioned in the memories above
- If the user asks about something NOT mentioned in the memories, say "I don't have that information in my memory yet. [Ask them to provide it]"
- NEVER make up information or make connections that aren't in the memories
- NEVER say "you mentioned earlier" or "you told me before" unless it's actually in the memories
- If the memories are not relevant to the current question, respond normally without referencing them
- Be direct and honest about what you know and don't know
- DO NOT include irrelevant information from memories in your response
- Pay attention to the relevance scores - higher scores indicate more important/relevant information

Current User Input: {user_input}

Assistant:"""
        else:
            prompt = f"""You are a helpful AI assistant with persistent memory capabilities. You can remember previous conversations and user preferences across multiple sessions.

I don't have any relevant memories for your current question.

CRITICAL RULES:
- Since there are no relevant memories, respond normally to the question
- DO NOT reference any previous conversations or memories
- DO NOT make up information about the user
- If the user asks about their preferences, facts, or personal information, say "I don't have that information in my memory yet. [Ask them to provide it]"
- Be helpful but honest about what you don't know
- Keep your response focused on the current question

Current User Input: {user_input}

Assistant:"""
        
        return prompt
    
    def _clean_response(self, response: str) -> str:
        """Clean up response to remove annoying filler words and improve quality"""
        
        # Remove common filler words at the beginning
        filler_words = [
            "Ah, ", "Ah! ", "Ah ", "Oh, ", "Oh! ", "Oh ", "Well, ", "Well! ", "Well ",
            "Hmm, ", "Hmm! ", "Hmm ", "Umm, ", "Umm! ", "Umm ", "So, ", "So! ", "So ",
            "Right, ", "Right! ", "Right ", "Okay, ", "Okay! ", "Okay "
        ]
        
        cleaned_response = response
        for filler in filler_words:
            if cleaned_response.startswith(filler):
                cleaned_response = cleaned_response[len(filler):]
                break
        
        # Remove multiple consecutive emojis (keep max 2)
        cleaned_response = re.sub(r'([ðŸ˜€-ðŸ™ðŸŒ€-ðŸ—¿ðŸš€-ðŸ›¿ðŸ¦€-ðŸ§¿]){3,}', r'\1\1', cleaned_response)
        
        # Remove excessive asterisks and formatting
        cleaned_response = re.sub(r'\*{3,}', '**', cleaned_response)
        
        # Clean up excessive whitespace
        cleaned_response = re.sub(r'\n{3,}', '\n\n', cleaned_response)
        cleaned_response = re.sub(r' {2,}', ' ', cleaned_response)
        
        return cleaned_response.strip()
    
    def _store_conversation(self, user_input: str, response: str):
        """Store conversation with enhanced metadata"""
        conversation_text = f"User: {user_input}\nAssistant: {response}"
        
        metadata = {
            "session_id": self.session_id,
            "conversation_turn": len(self.conversation_history) + 1,
            "user_input_length": len(user_input),
            "response_length": len(response),
        }
        
        memory_id = self.memory.add_conversation_memory(user_input, response)
        
        # Store in session history
        self.conversation_history.append({
            "id": memory_id,
            "user_input": user_input,
            "response": response,
            "timestamp": datetime.now().isoformat(),
            "session_id": self.session_id
        })
    
    def _extract_and_store_facts_intelligent(self, user_input: str, response: str):
        """Extract facts and preferences from conversation using LLM-powered extraction"""
        
        # Use the intelligent memory engine to process the conversation
        processing_result = self.memory_engine.process_conversation(user_input, response)
        
        # Log the processing results for debugging
        if processing_result.get("processed_memories"):
            print(f"Intelligent extraction processed: {len(processing_result['processed_memories'])} memories")
            for memory in processing_result["processed_memories"]:
                print(f"  - {memory}")
    
    def get_user_profile(self) -> Dict:
        """Get a summary of user information from memories"""
        preferences = self.memory.search_by_type("", "preference", top_k=10)
        facts = self.memory.search_by_type("", "fact", top_k=10)
        recent_conversations = self.memory.get_recent_memories(hours=24, limit=5)
        
        # Get memory analytics
        analytics = self.memory_engine.get_memory_analytics()
        
        return {
            "user_id": self.user_id,
            "preferences": [p.get('content', '') for p in preferences],
            "facts": [f.get('content', '') for f in facts],
            "recent_conversations": len(recent_conversations),
            "total_memories": len(self.memory.get_user_memories()),
            "memory_analytics": analytics
        }
    
    def search_memories(self, query: str, memory_type: str = None, top_k: int = 5) -> List[Dict]:
        """Search memories with optional type filtering using advanced retrieval"""
        if memory_type:
            memory_types = [memory_type]
        else:
            memory_types = None
        
        memories = self.advanced_retrieval.retrieve_memories_advanced(
            query, top_k, memory_types, min_relevance=0.2
        )
        
        # Get insights about the search
        insights = self.advanced_retrieval.get_memory_insights(query, memories)
        print(f"Search insights: {insights}")
        
        return memories
    
    def add_custom_memory(self, content: str, memory_type: str = "fact", importance: float = 1.0):
        """Add a custom memory"""
        return self.memory.add_memory(content, memory_type, importance)
    
    def get_conversation_history(self) -> List[Dict]:
        """Get the current session's conversation history"""
        return self.conversation_history
    
    def clear_user_memories(self) -> bool:
        """Clear all memories for the current user"""
        return self.memory.clear_user_memories()
    
    def get_memory_stats(self) -> Dict:
        """Get statistics about the user's memories"""
        all_memories = self.memory.get_user_memories()
        
        # Count by type
        type_counts = {}
        for memory in all_memories:
            memory_type = memory.get('metadata', {}).get('memory_type', 'unknown')
            type_counts[memory_type] = type_counts.get(memory_type, 0) + 1
        
        # Get advanced analytics
        analytics = self.memory_engine.get_memory_analytics()
        
        return {
            "total_memories": len(all_memories),
            "memory_types": type_counts,
            "user_id": self.user_id,
            "session_id": self.session_id,
            "advanced_analytics": analytics
        }
    
    def get_memory_insights(self, query: str) -> Dict:
        """Get detailed insights about memory retrieval for a query"""
        memories = self.advanced_retrieval.retrieve_memories_advanced(query, top_k=5)
        return self.advanced_retrieval.get_memory_insights(query, memories)

